{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"1. Introduction \u00b6 This guide serves as the main source of documentation for the ngs_pipeline.hg38_v1 . This is a comprehensive Snakemake workflow that can process RNAseq, Exome ( tumor only and Tumor-normal pairs) & TCRseq data. It involves a series of data processing, quality control steps followed by variant analysis, fusion calling, and annotation. All the tools used in this pipeline are listed here . containers. The Pipeline is currently hosted on NIH biowulf cluster and provides support hg38 genome. The pipeline is containerized via singularity and can be run on cloud platforms. This pipeline submits jobs to a cluster using a job schedules like slurm. This documentation provides a step to step walkthrough to understand and launch the pipeline. The output from this pipeline can be visualized using the oncogenomics_website . 2. Pipeline \u00b6 We follow tool suggested best practices for all the data processing. The pipeline can be launched using a yaml/json file. Metadata information like sample libraries, capture kit used, diagnosis, tumor-normal pairing are needed to create the yaml file. Detailed process can be found [here]. The pipeline can be run in RNAseq, tumor only and tumor-normal modes. // insert pipeline overview image // 2.1 Quality Control \u00b6 FastQC is a program designed to spot potential problems in high througput sequencing datasets. It provides an overview of basic quality control metrics for raw next generation sequencing data. The output is a html file summarizing several read statistics like Per base seqeunce quality, Per base GC content, Per seqeunce GC content, sequence length distribution, duplicated sequences and over represented sequences. Picard provides a high level metrics about the alignment of reads within a SAM/BAM file. This tool takes a SAM/BAM file input and produces metrics detailing the quality of the read alignments as well as the proportion of the reads that passed machine signal-to-noise threshold quality filters. RNAseQC The RNA-SeQC package has functions for computing various quality metrics, such as alignment quality, duplication rates, GC bias, rRNA content, coverage continuity, covered alignment regions, transcript count, and 3'/5' bias. It produces Read counts, coverage, correlation quality control metrics, and is also suitable for use with scRNA-seq data sets. Flagstat does a full pass through the input file to calculate and print statistics to stdout and Provides counts for each of 13 categories based primarily on bit flags in the FLAG field. Each category in the output is broken down into QC pass and QC fail. In the default output format, these are presented as \"#PASS + #FAIL\" followed by a description of the category. Circos Plots Genotyping Coverage Plots 2.2 Data Processing \u00b6 This comprehensive pipeline is capable of processing different sample libraries together and seperately. This scalable ngs workflows involves 1. RNA-seq sample processing 2. Tumor-Normal processing and 3. Tumor only processing. In Development References","title":"ngs_pipeline"},{"location":"#1-introduction","text":"This guide serves as the main source of documentation for the ngs_pipeline.hg38_v1 . This is a comprehensive Snakemake workflow that can process RNAseq, Exome ( tumor only and Tumor-normal pairs) & TCRseq data. It involves a series of data processing, quality control steps followed by variant analysis, fusion calling, and annotation. All the tools used in this pipeline are listed here . containers. The Pipeline is currently hosted on NIH biowulf cluster and provides support hg38 genome. The pipeline is containerized via singularity and can be run on cloud platforms. This pipeline submits jobs to a cluster using a job schedules like slurm. This documentation provides a step to step walkthrough to understand and launch the pipeline. The output from this pipeline can be visualized using the oncogenomics_website .","title":"1. Introduction"},{"location":"#2-pipeline","text":"We follow tool suggested best practices for all the data processing. The pipeline can be launched using a yaml/json file. Metadata information like sample libraries, capture kit used, diagnosis, tumor-normal pairing are needed to create the yaml file. Detailed process can be found [here]. The pipeline can be run in RNAseq, tumor only and tumor-normal modes. // insert pipeline overview image //","title":"2. Pipeline"},{"location":"#21-quality-control","text":"FastQC is a program designed to spot potential problems in high througput sequencing datasets. It provides an overview of basic quality control metrics for raw next generation sequencing data. The output is a html file summarizing several read statistics like Per base seqeunce quality, Per base GC content, Per seqeunce GC content, sequence length distribution, duplicated sequences and over represented sequences. Picard provides a high level metrics about the alignment of reads within a SAM/BAM file. This tool takes a SAM/BAM file input and produces metrics detailing the quality of the read alignments as well as the proportion of the reads that passed machine signal-to-noise threshold quality filters. RNAseQC The RNA-SeQC package has functions for computing various quality metrics, such as alignment quality, duplication rates, GC bias, rRNA content, coverage continuity, covered alignment regions, transcript count, and 3'/5' bias. It produces Read counts, coverage, correlation quality control metrics, and is also suitable for use with scRNA-seq data sets. Flagstat does a full pass through the input file to calculate and print statistics to stdout and Provides counts for each of 13 categories based primarily on bit flags in the FLAG field. Each category in the output is broken down into QC pass and QC fail. In the default output format, these are presented as \"#PASS + #FAIL\" followed by a description of the category. Circos Plots Genotyping Coverage Plots","title":"2.1 Quality Control"},{"location":"#22-data-processing","text":"This comprehensive pipeline is capable of processing different sample libraries together and seperately. This scalable ngs workflows involves 1. RNA-seq sample processing 2. Tumor-Normal processing and 3. Tumor only processing. In Development References","title":"2.2 Data Processing"},{"location":"overview/","text":"NGS pipeline can be launched using a yaml input file containing metadata information like Diagnosis, capture kit used, sample references and Sample type. The output of the ngs pipeline is uploaded to the Oncogenomics database. Master file must contain the following columns. The order of the columns doesnot matter. Patient ID Type Library ID FCID Diagnosis Enrichment step SampleRef Matched normal Matched RNA-seq lib Case Name Samplename tumor RNA Samplename_T1R_T AAAAAAAA5 Medulloblastoma access hg38 Test Samplename tumor DNA Samplename_T1D_E HMHAAAAA3 Medulloblastoma access hg38 Samplename_N1D_E Samplename_T1R_T Test Samplename blood DNA Samplename_N1D_E HMHYYYYY3 Medulloblastoma access hg38 Test Master file columns Values Patient ID Unique name of the Patient Type Format: \"[tumor/normal/cell line/blood/xeno] [RNA/DNA]\"; must be \"blood DNA\" or \"normal DNA\" to be recognized as \"Normal\", \"tumor DNA\" as \"Tumor\", or \"tumor RNA\" as \"RNAseq\" Library ID Sequencing library, in file name FCID Sequencing flow cell ID Diagnosis Cancer type Enrichment step Capture kit used. All currently supported kits are listed here under \"target_intervals\" Sampleref Accepted entries are hg19/hg38 Matched normal Library ID of normal DNA from same patient. Must be listed for tumor DNA only. Matched RNA-seq lib Library ID of tumor RNA from same patient. Must be listed for tumor DNA only Case Name Combine related samples that are jointly run with the pipeline, such as tumor/normal DNA + tumor RNA must be same as Case folder, should be meaningful (not date). Normal DNA can be assigned to multiple cases using comma-separated list When the pipeline runs, it will create a folder structure: Patient ID > Case Name > Library ID Use createyaml.py to create the yaml input file from the master file . Provide Patient ID, Case Name, and data location as arguments. python3 createyaml.py Samplename Test_Case </path to the master file> For a Patient sample containing RNAseq, Exome Tumor-normal pair, the pipeline runtime is ~22hrs. ------Add a table contianing no. of raw reads vs completion times. -------","title":"Getting Started"},{"location":"resources/","text":"Reference genomes Hg38 references used in this pipeline are downloaded from gencode . All the genome indexes are build using these fasta and gtf files. files Species Annotation Version Notes Genome fasta Homo sapiens Gencode release v39 92 sequences of ERCC spike in are added to the fasta file Annotation GTF Homo sapiens Gencode release v39 92 sequences of ERCC spike in are appended to the gtf file Tools and versions Tool Version snakemake 5.24.1 Graphviz v 2.40.1 annovar 4/16/18 arriba 2.0.0 bamutil 1.0.13 bedtools 2.22.0 bowtie 1.1.1 bwa 0.7.10 cnvkit 0.9.3 conpair 10102016 fastqc 0.11.2 fusioncatcher 1 GATK 3.4-0 mixcr 2.1.12 GATK 3.8-1 GATK 4.1.8.0 igvtools 2.3.31 java 1.8.0_11 manta 1.6.0 STAR 2.7.6a muTect 1.1.7 picard 1.129 python 2.7 python 3.7 R 3.4 R 4.0.5 rnaseqc 1.1.8 rsem 1.3.0 bcftools 1.13 samtools 0.1.19 VEP 86 samtools 1.9 sequenza-utils 3.0.0 SIFT 5.2.2 singularity snpEff 4.1c STAR 2.7.8a STAR-Fusion 1.3.1 strelka 2.9.10 vcftools 0.1.13 vdjtools 1.1.10 verifybamid 1.1.3","title":"Resources"},{"location":"usage/","text":"Running the pipeline \u00b6 The ngs pipeline can be run using a wrapper bash script and the input yaml file. This wrapper calls the launch script. Wrapper script can be set up as below. #!/bin/sh samplesheet=$1 a=`echo $samplesheet |sed -e 's/_/\\t/' |sed -e 's/.json//g' |cut -f2` /data/Clinomics/Tools/ngs_pipeline.hg38_v1/launch -d /path/to/data/directory/ -w /path/to/output/directory/ -s /path/to/yaml/${samplesheet} -m $a $2 Arguments launch -datadir <path to data directory> -workdir <Path to the results directory> -s <yaml file path > Arguments: -h, -help, --help Print this message. -d, -datadir On biowulf the raw data is stored in /data/khanlab/projects/DATA/ On TGen the raw data is stored in /projects/Clinomics/DATA/ If your data is coming from somewhere else specify using this variable -datadir \"/data/Clinomics/testData/\" -w, -workdir Working directory where all the results will be stored. there are defaults to be used specific to host. -s, -sheet A yaml file can be downloded from https://fr-s-bsg-onc-d.ncifcrf.gov/onco.sandbox1/public/viewPatients/null/all/1 or can be create using the createyaml.py script. This dictates how the pipeline will run Always do a dry run of the sample before launching the pipeline. This way we can ensure that all the steps are listed accurately and fix any irregularities. ./run.sh Samplename_TestCase.yaml --dryrun Once the dry run looks good, the sample can be launched as below. The jobs will be submitted via sbatch to the slurm process. ./run.sh Samplename_TestCase.yaml","title":"Usage"},{"location":"usage/#running-the-pipeline","text":"The ngs pipeline can be run using a wrapper bash script and the input yaml file. This wrapper calls the launch script. Wrapper script can be set up as below. #!/bin/sh samplesheet=$1 a=`echo $samplesheet |sed -e 's/_/\\t/' |sed -e 's/.json//g' |cut -f2` /data/Clinomics/Tools/ngs_pipeline.hg38_v1/launch -d /path/to/data/directory/ -w /path/to/output/directory/ -s /path/to/yaml/${samplesheet} -m $a $2 Arguments launch -datadir <path to data directory> -workdir <Path to the results directory> -s <yaml file path > Arguments: -h, -help, --help Print this message. -d, -datadir On biowulf the raw data is stored in /data/khanlab/projects/DATA/ On TGen the raw data is stored in /projects/Clinomics/DATA/ If your data is coming from somewhere else specify using this variable -datadir \"/data/Clinomics/testData/\" -w, -workdir Working directory where all the results will be stored. there are defaults to be used specific to host. -s, -sheet A yaml file can be downloded from https://fr-s-bsg-onc-d.ncifcrf.gov/onco.sandbox1/public/viewPatients/null/all/1 or can be create using the createyaml.py script. This dictates how the pipeline will run Always do a dry run of the sample before launching the pipeline. This way we can ensure that all the steps are listed accurately and fix any irregularities. ./run.sh Samplename_TestCase.yaml --dryrun Once the dry run looks good, the sample can be launched as below. The jobs will be submitted via sbatch to the slurm process. ./run.sh Samplename_TestCase.yaml","title":"Running the pipeline"},{"location":"RNAseq/rnaseq/","text":"1. Overview \u00b6 RNA-sequencing has wide variety of applications. The power of sequencing RNA lies in the fact that the twin aspects of discovery and quantification can be combined in a single high-throughput sequencing assay called RNA-sequencing. RNA-seq can be coupled with different types of biochemical assay to analyze many other aspects of RNA biology, such as RNA\u2013protein binding, RNA structure, or RNA\u2013RNA interactions. This pipeline presents optimal methods for transcript quantification, fusion detection, variant analysis and QC. 2. Mapping \u00b6 STAR aligner is designed to specifically address many of the challenges of RNA-seq data mapping using a strategy to account for spliced alignments. STAR aligns the non-contiguous sequences directly to the reference genome. We use STAR \"TwopassMode\"; in the first pass, the novel junctions are detected and inserted into the genome indices. In the second pass, all reads will be re-mapped using annotated (from the GTF file) and novel (detected in the first pass) junctions. While this doubles the run time, it significantly increases sensitivity to novel splice junctions. The genome versions and the tool versions are listed here . We generate two bam files from the STAR alignment. Bam Purpose Transcriptome bam For gene Quantification Genome bam For variant analysis 3. Quantification \u00b6 RSEM is an accurate and user-friendly software tool for estimating gene and isoform expression levels from RNA-Seq data. The RSEM package supports threads for parallel computation of the EM algorithm, single-end and paired-end read data, quality scores, variable-length reads and RSPD estimation. In addition, it provides posterior mean and 95% credibility interval estimates for expression levels. 4. Fusion Detection \u00b6 Arriba is a command-line tool for the detection of gene fusions from RNA-Seq data. It is based on the ultrafast STAR aligner, and renders detailed quality visualizations of the transcripts involved in predicted fusions. It generates a PDF file with one page for each predicted fusion. Each page depicts the fusion partners, their orientation, the retained exons in the fusion transcript and statistics about the number of supporting reads. STAR-Fusion is a component of the Trinity Cancer Transcriptome Analysis Toolkit (CTAT). STAR-Fusion uses the STAR aligner to identify candidate fusion transcripts supported by Illumina reads. STAR-Fusion further processes the output generated by the STAR aligner to map junction reads and spanning reads to a reference annotation set. STAR-Fusion can be run using fastq files as input or using the 'Chimeric.junction.out' file from STAR mapping. This pipeline uses the later technique. FusionCatcher searches for somatic novel/known fusion genes, translocations and/or chimeras in RNA-seq data. FusionCatcher achieves competitive detection rates and real-time PCR validation rates in RNA-sequencing data from tumor cells. 4. Variant Analysis \u00b6 We are using GATK3 for RNAseq analysis. Picard is used to addReadGroups and mark duplicates to the STAR bam followed by GATK analysis. SplitNTrim is an RNAseq-specific step: reads with N operators in the CIGAR strings (which denote the presence of a splice junction) are split into component reads and trimmed to remove any overhangs into splice junctions, which reduces the occurrence of artifacts. At this step, we also reassign mapping qualities from 255 (assigned by STAR) to 60 which is more meaningful for GATK tools RealignTargetCreator IndelRealigner local realignment is performed around indels, because the algorithms that are used in the initial mapping step tend to produce various types of artifacts. For example, reads that align on the edges of indels often get mapped with mismatching bases that might look like evidence for SNPs, but are actually mapping artifacts. The realignment process identifies the most consistent placement of the reads relative to the indel in order to clean up these artifacts. It occurs in two steps: first the program identifies intervals that need to be realigned, then in the second step it determines the optimal consensus sequence and performs the actual realignment of reads. This step is considered optional for RNAseq. Base Quality Score Recalibration Finally, base quality scores are recalibrated, because the variant calling algorithms rely heavily on the quality scores assigned to the individual base calls in each sequence read. These scores are per-base estimates of error emitted by the sequencing machines. Unfortunately the scores produced by the machines are subject to various sources of systematic error, leading to over- or under-estimated base quality scores in the data. Base quality score recalibration is a process in which we apply machine learning to model these errors empirically and adjust the quality scores accordingly. This yields more accurate base qualities, which in turn improves the accuracy of the variant calls. The base recalibration process involves two key steps: first the program builds a model of covariation based on the data and a set of known variants, then it adjusts the base quality scores in the data based on the model. 5. Germline variant analysis \u00b6 6. Annovar - Annotation \u00b6","title":"RNAseq Analysis"},{"location":"RNAseq/rnaseq/#1-overview","text":"RNA-sequencing has wide variety of applications. The power of sequencing RNA lies in the fact that the twin aspects of discovery and quantification can be combined in a single high-throughput sequencing assay called RNA-sequencing. RNA-seq can be coupled with different types of biochemical assay to analyze many other aspects of RNA biology, such as RNA\u2013protein binding, RNA structure, or RNA\u2013RNA interactions. This pipeline presents optimal methods for transcript quantification, fusion detection, variant analysis and QC.","title":"1. Overview"},{"location":"RNAseq/rnaseq/#2-mapping","text":"STAR aligner is designed to specifically address many of the challenges of RNA-seq data mapping using a strategy to account for spliced alignments. STAR aligns the non-contiguous sequences directly to the reference genome. We use STAR \"TwopassMode\"; in the first pass, the novel junctions are detected and inserted into the genome indices. In the second pass, all reads will be re-mapped using annotated (from the GTF file) and novel (detected in the first pass) junctions. While this doubles the run time, it significantly increases sensitivity to novel splice junctions. The genome versions and the tool versions are listed here . We generate two bam files from the STAR alignment. Bam Purpose Transcriptome bam For gene Quantification Genome bam For variant analysis","title":"2. Mapping"},{"location":"RNAseq/rnaseq/#3-quantification","text":"RSEM is an accurate and user-friendly software tool for estimating gene and isoform expression levels from RNA-Seq data. The RSEM package supports threads for parallel computation of the EM algorithm, single-end and paired-end read data, quality scores, variable-length reads and RSPD estimation. In addition, it provides posterior mean and 95% credibility interval estimates for expression levels.","title":"3. Quantification"},{"location":"RNAseq/rnaseq/#4-fusion-detection","text":"Arriba is a command-line tool for the detection of gene fusions from RNA-Seq data. It is based on the ultrafast STAR aligner, and renders detailed quality visualizations of the transcripts involved in predicted fusions. It generates a PDF file with one page for each predicted fusion. Each page depicts the fusion partners, their orientation, the retained exons in the fusion transcript and statistics about the number of supporting reads. STAR-Fusion is a component of the Trinity Cancer Transcriptome Analysis Toolkit (CTAT). STAR-Fusion uses the STAR aligner to identify candidate fusion transcripts supported by Illumina reads. STAR-Fusion further processes the output generated by the STAR aligner to map junction reads and spanning reads to a reference annotation set. STAR-Fusion can be run using fastq files as input or using the 'Chimeric.junction.out' file from STAR mapping. This pipeline uses the later technique. FusionCatcher searches for somatic novel/known fusion genes, translocations and/or chimeras in RNA-seq data. FusionCatcher achieves competitive detection rates and real-time PCR validation rates in RNA-sequencing data from tumor cells.","title":"4. Fusion Detection"},{"location":"RNAseq/rnaseq/#4-variant-analysis","text":"We are using GATK3 for RNAseq analysis. Picard is used to addReadGroups and mark duplicates to the STAR bam followed by GATK analysis. SplitNTrim is an RNAseq-specific step: reads with N operators in the CIGAR strings (which denote the presence of a splice junction) are split into component reads and trimmed to remove any overhangs into splice junctions, which reduces the occurrence of artifacts. At this step, we also reassign mapping qualities from 255 (assigned by STAR) to 60 which is more meaningful for GATK tools RealignTargetCreator IndelRealigner local realignment is performed around indels, because the algorithms that are used in the initial mapping step tend to produce various types of artifacts. For example, reads that align on the edges of indels often get mapped with mismatching bases that might look like evidence for SNPs, but are actually mapping artifacts. The realignment process identifies the most consistent placement of the reads relative to the indel in order to clean up these artifacts. It occurs in two steps: first the program identifies intervals that need to be realigned, then in the second step it determines the optimal consensus sequence and performs the actual realignment of reads. This step is considered optional for RNAseq. Base Quality Score Recalibration Finally, base quality scores are recalibrated, because the variant calling algorithms rely heavily on the quality scores assigned to the individual base calls in each sequence read. These scores are per-base estimates of error emitted by the sequencing machines. Unfortunately the scores produced by the machines are subject to various sources of systematic error, leading to over- or under-estimated base quality scores in the data. Base quality score recalibration is a process in which we apply machine learning to model these errors empirically and adjust the quality scores accordingly. This yields more accurate base qualities, which in turn improves the accuracy of the variant calls. The base recalibration process involves two key steps: first the program builds a model of covariation based on the data and a set of known variants, then it adjusts the base quality scores in the data based on the model.","title":"4. Variant Analysis"},{"location":"RNAseq/rnaseq/#5-germline-variant-analysis","text":"","title":"5. Germline variant analysis"},{"location":"RNAseq/rnaseq/#6-annovar-annotation","text":"","title":"6. Annovar - Annotation"},{"location":"Tumor_only/tumor/","text":"Tumor only sequecing is usually done when a matching normal is not available. This pipeline can handle such smaples and run soamtic Variant analysis and thourough QC.","title":"Tumor only Analysis"},{"location":"exomeTN/exomeTN/","text":"1.Overview \u00b6 Exome sequencing allows cancer researchers to assess only coding regions, which frequently contain mutations that affect tumor progression. Depending on experimental needs, the content for cancer exome sequencing can also be expanded to untranslated regions and microRNA (miRNA) binding sites. Because it offers an accessible combination of turnaround time and price, exome sequencing is the method of choice for many tumor-normal comparisons. Tumor-normal comparisons are crucial for identifying the somatic variants that act as driver mutations in cancer progression. 2. Mapping \u00b6 BWA is a software package for mapping low-divergent sequences against a large reference genome, such as the human genome. We use BWA-mem which is generally recommended for high-quality queries as it is faster and more accurate. BWA-MEM also has better performance than BWA-backtrack for 70-100bp Illumina reads. 3. Picard \u00b6 4. Variant Analysis \u00b6 a. Somatic Variant Calling \u00b6 Strelka calls somatic small variants from mapped sequencing reads in tumor/normal sample pairs. Strelka accepts input read mappings from BAM or CRAM files, and optionally candidate and/or forced-call alleles from VCF. For best somatic indel performance, Strelka is designed to be run with the Manta structural variant and indel caller, which provides additional indel candidates up to a given maxiumum indel size (by default this is 49). By design, Manta and Strelka run together with default settings provide complete coverage over all indel sizes (in additional to all SVs and SNVs) for clinical somatic analysis. MuTect b. Germline Variant Calling \u00b6 Seq2HLA HLAminer HLA prediction by targeted assembly of short sequence reads (HPTASR), performs targeted de novo assembly of HLA NGS reads and align the resulting contigs to reference HLA alleles from the IMGT/HLA sequence repository using commodity hardware with standard specifications (<2GB RAM, 2GHz). Putative HLA types are inferred by mining and scoring the contig alignments and an expect value is determined for each. The method is accurate, simple and fast to execute and, for transcriptome data, requires low depth of coverage. HaplotypeCaller is capable of calling SNPs and indels simultaneously via local de-novo assembly of haplotypes in an active region 5. Variant Annotation \u00b6 6. Copy number Analysis \u00b6 CNVkit is a Python library and command-line software toolkit to infer and visualize copy number from high-throughput DNA sequencing data. 7. Mutation Burden & Mutational Signatures \u00b6","title":"Exome Tumor-Normal Analysis"},{"location":"exomeTN/exomeTN/#1overview","text":"Exome sequencing allows cancer researchers to assess only coding regions, which frequently contain mutations that affect tumor progression. Depending on experimental needs, the content for cancer exome sequencing can also be expanded to untranslated regions and microRNA (miRNA) binding sites. Because it offers an accessible combination of turnaround time and price, exome sequencing is the method of choice for many tumor-normal comparisons. Tumor-normal comparisons are crucial for identifying the somatic variants that act as driver mutations in cancer progression.","title":"1.Overview"},{"location":"exomeTN/exomeTN/#2-mapping","text":"BWA is a software package for mapping low-divergent sequences against a large reference genome, such as the human genome. We use BWA-mem which is generally recommended for high-quality queries as it is faster and more accurate. BWA-MEM also has better performance than BWA-backtrack for 70-100bp Illumina reads.","title":"2. Mapping"},{"location":"exomeTN/exomeTN/#3-picard","text":"","title":"3. Picard"},{"location":"exomeTN/exomeTN/#4-variant-analysis","text":"","title":"4. Variant Analysis"},{"location":"exomeTN/exomeTN/#a-somatic-variant-calling","text":"Strelka calls somatic small variants from mapped sequencing reads in tumor/normal sample pairs. Strelka accepts input read mappings from BAM or CRAM files, and optionally candidate and/or forced-call alleles from VCF. For best somatic indel performance, Strelka is designed to be run with the Manta structural variant and indel caller, which provides additional indel candidates up to a given maxiumum indel size (by default this is 49). By design, Manta and Strelka run together with default settings provide complete coverage over all indel sizes (in additional to all SVs and SNVs) for clinical somatic analysis. MuTect","title":"a. Somatic Variant Calling"},{"location":"exomeTN/exomeTN/#b-germline-variant-calling","text":"Seq2HLA HLAminer HLA prediction by targeted assembly of short sequence reads (HPTASR), performs targeted de novo assembly of HLA NGS reads and align the resulting contigs to reference HLA alleles from the IMGT/HLA sequence repository using commodity hardware with standard specifications (<2GB RAM, 2GHz). Putative HLA types are inferred by mining and scoring the contig alignments and an expect value is determined for each. The method is accurate, simple and fast to execute and, for transcriptome data, requires low depth of coverage. HaplotypeCaller is capable of calling SNPs and indels simultaneously via local de-novo assembly of haplotypes in an active region","title":"b. Germline Variant Calling"},{"location":"exomeTN/exomeTN/#5-variant-annotation","text":"","title":"5. Variant Annotation"},{"location":"exomeTN/exomeTN/#6-copy-number-analysis","text":"CNVkit is a Python library and command-line software toolkit to infer and visualize copy number from high-throughput DNA sequencing data.","title":"6. Copy number Analysis"},{"location":"exomeTN/exomeTN/#7-mutation-burden-mutational-signatures","text":"","title":"7. Mutation Burden &amp; Mutational Signatures"}]}